"""Gemini AI service for LLM and Vision operations."""

import base64
import json
from typing import Any

import google.generativeai as genai

from app.core.config import settings


class GeminiService:
    """Service for Gemini LLM and Vision capabilities."""

    def __init__(self) -> None:
        # Vertex AIê°€ ì•„ë‹Œ Google AI Studio API í‚¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° configure í•„ìš”
        # Vertex AI í™˜ê²½(GCP)ì´ë¼ë©´ ì´ˆê¸°í™” ë°©ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‚˜,
        # í˜„ì¬ ì½”ë“œ ë² ì´ìŠ¤ëŠ” api_key ë°©ì‹ì„ ë”°ë¦…ë‹ˆë‹¤.
        genai.configure(api_key=settings.GEMINI_API_KEY)
        self._model = None
        self._vision_model = None

        # ğŸš€ [Upgrade] ìµœì‹  Gemini 2.0 ëª¨ë¸ ì‚¬ìš©
        # ë§Œì•½ ì—ëŸ¬ ë°œìƒ ì‹œ "gemini-1.5-flash-001"ë¡œ ë³€ê²½í•˜ì„¸ìš”.
        self.MODEL_NAME = "gemini-2.0-flash-lite-001"

    @property
    def model(self):
        """Get text generation model."""
        if self._model is None:
            self._model = genai.GenerativeModel(self.MODEL_NAME)
        return self._model

    @property
    def vision_model(self):
        """Get vision-capable model."""
        if self._vision_model is None:
            self._vision_model = genai.GenerativeModel(self.MODEL_NAME)
        return self._vision_model

    def _parse_json_response(self, response_text: str) -> dict | list:
        """Helper to cleanly parse JSON from LLM response."""
        try:
            json_str = response_text
            if "```json" in response_text:
                json_str = response_text.split("```json")[1].split("```")[0]
            elif "```" in response_text:
                json_str = response_text.split("```")[1].split("```")[0]

            return json.loads(json_str.strip())
        except (json.JSONDecodeError, IndexError):
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì—ëŸ¬ êµ¬ì¡° ë°˜í™˜ ë˜ëŠ” ë¹ˆ ê°’ ë°˜í™˜
            return {}

    def generate_text(
        self,
        prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> str:
        """
        Generate text response from a prompt.
        """
        generation_config = genai.GenerationConfig(
            temperature=temperature,
            max_output_tokens=max_tokens,
        )

        try:
            response = self.model.generate_content(
                prompt,
                generation_config=generation_config,
            )
            return response.text
        except Exception as e:
            print(f"Gemini generation error: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. AI ëª¨ë¸ ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def analyze_transcript(
        self,
        transcript: str,
        agenda: str | None = None,
    ) -> dict[str, Any]:
        """
        Analyze meeting transcript to extract decisions and action items.
        """
        agenda_section = f"íšŒì˜ ì•ˆê±´ì§€:\n{agenda}\n\n" if agenda else ""
        prompt = f"""ë‹¤ìŒ íšŒì˜ ì†ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ê²°ì • ì‚¬í•­ê³¼ ì•¡ì…˜ ì•„ì´í…œì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

{agenda_section}íšŒì˜ ì†ê¸°ë¡:
{transcript}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µì„ í•´ì£¼ì„¸ìš”:
{{
    "summary": "íšŒì˜ ìš”ì•½ (2-3ë¬¸ì¥)",
    "decisions": [
        {{"topic": "ë…¼ì˜ ì£¼ì œ", "decision": "ê²°ì • ë‚´ìš©"}}
    ],
    "action_items": [
        {{"task": "í•  ì¼", "assignee": "ë‹´ë‹¹ì (ì—†ìœ¼ë©´ null)", "due_date": "ë§ˆê°ì¼ (ì—†ìœ¼ë©´ null)"}}
    ]
}}
"""
        response_text = self.generate_text(prompt, temperature=0.3)
        result = self._parse_json_response(response_text)

        if not result:
            return {
                "summary": response_text,
                "decisions": [],
                "action_items": [],
            }
        return result

    def caption_image(
        self,
        image_bytes: bytes,
        mime_type: str = "image/jpeg",
    ) -> str:
        """
        Generate a caption/description for an image.
        """
        prompt = """ì´ ì´ë¯¸ì§€ê°€ í‘œë‚˜ ì¡°ì§ë„ë¼ë©´ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ êµ¬ì¡°ë¥¼ í…ìŠ¤íŠ¸í™”í•˜ê³ ,
ì¼ë°˜ ì‚¬ì§„ì´ë¼ë©´ ìƒí™©ì„ ìƒì„¸ ë¬˜ì‚¬í•´ ì¤˜. í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        image_part = {
            "inline_data": {
                "mime_type": mime_type,
                "data": base64.b64encode(image_bytes).decode("utf-8"),
            }
        }

        try:
            response = self.vision_model.generate_content([prompt, image_part])
            return response.text
        except Exception as e:
            print(f"Vision generation error: {e}")
            return "ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def generate_answer(
        self,
        query: str,
        context: list[str],
        chat_history: str | None = None,
        partner_info: dict | None = None,
    ) -> str:
        """
        Generate an answer based on retrieved context (RAG).
        """
        context_text = "\n\n---\n\n".join(context) if context else "(ê²€ìƒ‰ëœ ë¬¸ì„œ ì—†ìŒ)"

        history_section = ""
        if chat_history and chat_history != "(ì´ì „ ëŒ€í™” ì—†ìŒ)":
            history_section = f"""
## ì´ì „ ëŒ€í™” (Context)
{chat_history}
"""

        partner_section = ""
        if partner_info:
            partner_section = f"""
## ì œíœ´ ì—…ì²´ ì •ë³´ (ì°¸ê³ )
{partner_info}
"""

        prompt = f"""ë‹¹ì‹ ì€ í•™ìƒíšŒ ì—…ë¬´ë¥¼ ë•ëŠ” AI ë¹„ì„œ 'Council-AI'ì…ë‹ˆë‹¤.

## ì—­í• 
- ì œê³µëœ [ê²€ìƒ‰ëœ ë¬¸ì„œ]ë¥¼ ìµœìš°ì„  ê·¼ê±°ë¡œ ì‚¬ìš©í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.
- [ì œíœ´ ì—…ì²´ ì •ë³´]ê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆë‹¤ë©´ ì ê·¹ì ìœ¼ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ì•Šê³ , "í•´ë‹¹ ì •ë³´ë¥¼ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•©ë‹ˆë‹¤.
- [ì´ì „ ëŒ€í™”]ì˜ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬, ì‚¬ìš©ìê°€ 'ê·¸ê±°', 'ì €ê±°'ë¡œ ì§€ì¹­í•œ ëŒ€ìƒì„ íŒŒì•…í•©ë‹ˆë‹¤.

## ê²€ìƒ‰ëœ ë¬¸ì„œ
{context_text}
{partner_section}{history_section}
## ì‚¬ìš©ì ì§ˆë¬¸
{query}

## ë‹µë³€ ê°€ì´ë“œë¼ì¸
1. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ìœ ì§€í•©ë‹ˆë‹¤.
2. í•µì‹¬ ê²°ë¡ ì„ ë‘ê´„ì‹ìœ¼ë¡œ ë¨¼ì € ì œì‹œí•©ë‹ˆë‹¤.
3. ì •ë³´ê°€ ë‚˜ì—´ë  ê²½ìš° ë§ˆí¬ë‹¤ìš´ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë‚˜ í‘œë¥¼ ì‚¬ìš©í•´ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.
4. ì¶œì²˜ê°€ ëª…í™•í•œ ê²½ìš° "(ì¶œì²˜: ë¬¸ì„œëª…)"ê³¼ ê°™ì´ í‘œê¸°í•©ë‹ˆë‹¤.

## ë‹µë³€:"""

        # RAG ë‹µë³€ì€ ì‚¬ì‹¤ ê¸°ë°˜ì´ì–´ì•¼ í•˜ë¯€ë¡œ temperatureë¥¼ ë‚®ê²Œ ì„¤ì •
        return self.generate_text(prompt, temperature=0.1)

    def extract_calendar_events(self, text: str) -> list[dict[str, Any]]:
        """
        Extract calendar event information from text.
        """
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ìº˜ë¦°ë”ì— ë“±ë¡í•  ì¼ì • ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸:
{text}

ë‹¤ìŒ í˜•ì‹ì˜ JSON ë°°ì—´ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
[
    {{
        "title": "ì¼ì • ì œëª©",
        "date": "YYYY-MM-DD",
        "time": "HH:MM (ì—†ìœ¼ë©´ null)",
        "assignee": "ë‹´ë‹¹ì (ì—†ìœ¼ë©´ null)",
        "description": "ìƒì„¸ ë‚´ìš©"
    }}
]
"""
        response_text = self.generate_text(prompt, temperature=0.2)
        result = self._parse_json_response(response_text)

        return result if isinstance(result, list) else []
